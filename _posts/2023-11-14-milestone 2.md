## 2. Feature engineering I
### A histogram of shot counts binned by distance
![Alt text](../assets/milestone2/question2/shot-by-distance-hist.png)

Shots and goals are more frequent at lower net distance, which indicates that shots taken closer to the net have a higher success rate.

### A histogram of shot counts binned by angle
![Alt text](../assets/milestone2/question2/shot-by-angle-hist.png)

The distribution appears to be symmetric around the 0 degrees angle. There are prominent peaks near the center, which correspond to shots taken from directly in front of the net. The high number of shots and goals in this area suggests that straight-on shots are more common and successful.

### A 2D histogram where one axis is the distance and the other is the angle.
![Alt text](../assets/milestone2/question2/join-plot-hist.png)

There is a sparse distribution of shots at greater distances, indicating that shots are less frequently taken from far away. As the distance from the net increases, the spread of angles from which shots are taken appears to decrease. This suggests that long-distance shots are less likely to be taken from wide angle.

### A histogram of average goal rate vs distance bins
![Alt text](../assets/milestone2/question2/Goal_rate_vs_distance.png)

Now we have calculated the goal rate which is the efficiency of goal scoring attempts. As seen from the bar plot we can see that the efficiency is more at the distance [0-20] since it's near the goal post. The interesting thing is that the efficiency increases at higher distances. Even though there were less shots in higher distance, the efficiency of scoring a goal is much better than distances in the middle. 

### A histogram of average goal rate vs angle bins
![Alt text](../assets/milestone2/question2/Goal_rate_vs_angle.png)

The goal rate seems to follow a similar trend that of the shot counts. So the efficiency of the goal is almost directly proportional to the shots taken. SInce there are more shots between the angle -20 to 20 also the efficiency of the goal is also high at those angles especially angles between -10 to 10 is the highest since these are shots taken directly in front of the net. As discussed the straight-on shots lead to a higer goal rate. 


### A histogram of goals count binned by distance.
![Alt text](../assets/milestone2/question2/goals_hist.png)
A significant majority of goals are scored from a close distance. There are very few goals scored on an empty net. They are spread out over a range of distances, including some from very long range. The non-empty net goals are rarely scored from distances beyond 75 feet, underscoring the difficulty of scoring long-range goals with the presence of goalie.

Regarding to the domain knowledge: “it is incredibly rare to score a non-empty net goal on the opposing team from within your defensive zone”, a histogram of goals from teams'defensive zone is created as below.

![Alt text](../assets/milestone2/question2/goal_defensive_zone_hist.png)

The histogram reveals that scoring a non-empty-net goal on the opposing team from the team's defensive zone is indeed a rare event. The distribution suggests that these occurrences are relatively random and are not heavily influenced by the distance from the goal. Additionally, it's noted that some goal data may be recorded incorrectly, with one example is the first goal of game 2018020722 at 04:39, 1st period. The x/y coordinates has been recorded incorrectly to -85 and -22 respectively. For verification and context, game highlights are available through the provided [link](https://www.nhl.com/gamecenter/bos-vs-phi/2019/01/16/2018020722/playbyplay). 

## 3. BaseLine Models

We created a training and validation split and used net_distance from out train dataset to predict binanry classification of is_goal in our dataset and calculated the accuracy. The accuracy we were getting was 0.90 which is a good one. But then after looking at the predictions we noticed that most of the values were 0. When we used y_pred.sum(), the result was 0. This lead to the conclusion that the data is imbalanced and the class 0 is overrepresented. In hockey, it's common knowledge that goals are rarely scored, hence class 0 represents the amount of goals that were missed. 

### Logistic Regression Trained on Distance. 
![Alt text](../assets/milestone2/Question3/logreg_net_distance.png)

[link](https://www.comet.com/duyhung2201/ift-6758-b03-project/423ac86f42e4421fa6a588f1a0235284?experiment-tab=panels&showOutliers=true&smoothing=0&xAxis=step)
[link](https://www.comet.com/duyhung2201/model-registry/logisitc_regression_-net_distance/1.23.0?tab=assets)

ROC Curve: The AUC metrics = 0.69 shows that the model is able to discriminate between the positive and negative instances moderately. 

Gaol Rate: This graph shows a decreasing trend which shows that at the percentile decreases the goal rate also decreases. Therefore at the highest predicted probability the goal rate is at it's max. 

Cummulative Proportion of goal: This graph shows that at highest percentile there isnt any cummulation of goals. SO as the percentile decreases the accumulation of goal increases. Therefore at the highest predicted probability, there arent any accumulation of goals and vise versa. 

Reliability Diagram: The line follows the "Perfectly Calibrated" untill 0.2 and deviates from it and jumps to 0.7. This might indicate that the model predicted probability is only reliable untill 0.2. 

### Logistic Regression Trained on shot_angle
![Alt text](../assets/milestone2/Question3/logreg_shot_angle.png)

[link](https://www.comet.com/duyhung2201/ift-6758-b03-project/135ea67112774af49a64e27c219b972c?experiment-tab=panels&showOutliers=true&smoothing=0&xAxis=step)
[link](https://www.comet.com/duyhung2201/model-registry/logisitc_regression_-shot_angle/1.11.0?tab=assets)

ROC Curve: The  AUC metrics = 0.51 indicates that the model is very close in being random. That is it is predicting the labels in a random manner. It is very close to not being able to discriminate the positive and negative instenses. 

Goal Rate: Since the AUC = 0.51 the model is not able to assign hight goal rate to highest predicted probability. The goal rate is 5% at percentile 0 and also 5% at 100 percentile and almost remains close to constant of 5% at every percentile. 

Cummulative Proportion of goal: Since the model is not able to discriminate properly there is almost close to being a uniform increase and decrease in accumulation of goal and percentile. 

Reliability Diagram: Having only one dot on the "Perfectly Calibrated" tells us that there is only limited infirmation. So the angle feature alone is not enough to predict the probability of being a goal or not. 

### Logistic Regression Trained on net_distance and shot_angle. 
![Alt text](../assets/milestone2/Question3/angle_distance.png)

[link](https://www.comet.com/duyhung2201/ift-6758-b03-project/c3d0f5cc9085462ea455b3d127b3c55e?experiment-tab=panels&showOutliers=true&smoothing=0&xAxis=step)
[link](https://www.comet.com/duyhung2201/model-registry/logisitc_regression_-shot_angle-net_distance/1.11.0?tab=assets)

As seen from the net_distance the AUC score, goal rate , accumulation of goals and reliability diagram are all similar except the goal rate for this graph starts from 30%. This indicates that the model is not able to train well with the shot_angle feature properly. 

### Using Random Baseline.
![Alt text](../assets/milestone2/Question3/Random_classifier.png)

[link](https://www.comet.com/duyhung2201/ift-6758-b03-project/78e1833e53fa4a989067cd580382dbef?experiment-tab=params)
[link](https://www.comet.com/duyhung2201/model-registry/random_classifier_/1.31.0?tab=assets)

The AUC score is 0.50 since the model does not have any discriminative power. We can also see that the goal rate is very stationary at the around 9.3 to 10 for all values of percentile. The Accumulation of goal has a very unifrom increase and decrease in accumulation of goal and percentile. Since the model is random it is not very well calibrated and has very less information to make predictions since it has only one point. 

## 4. Feature engineering II

In the dataset we're working with, each feature provides unique and insightful data regarding the events of NHL games. Here is a breakdown of each feature:

- `game_id`: The unique identifier for each game.
- `event`: Type of event being recorded, such as a 'SHOT' or 'GOAL'.
- `prev_event`: The event that immediately precedes the current event.
- `period`: The period of the game in which the event occurred (1, 2, 3 for regular time, additional for overtime).
- `date_time`: The real-world date and time at which the event happened.
- `period_time`: The time on the game clock when the event occurred.
- `game_seconds`: Total number of seconds elapsed in the game when the event occurred.
- `time_from_pre_event`: The time elapsed since the previous event.
- `prev_team`: The team that made the previous event.
- `team`: The team that is associated with the current event.
- `x_coordinate`: The x-coordinate on the rink where the event occurred.
- `y_coordinate`: The y-coordinate on the rink where the event occurred.
- `prev_x_coordinate`: The x-coordinate of the previous event.
- `prev_y_coordinate`: The y-coordinate of the previous event.
- `shooter_name`: The name of the player who took the shot.
- `goalie_name`: The name of the goalie involved in the event.
- `shot_type`: The type of shot taken (e.g., slap shot, wrist shot).
- `empty_net`: Indicates whether the goal was empty when the shot was taken.
- `strength`: The strength of the team during the event (e.g., even strength, power play).
- `power_play_elapsed_time`: This feature tracks the time elapsed during a team's power play. It resets to zero once the power play ends.
- `friendly_non_goalie_skater`: This feature counts the number of skaters, excluding goalies, for the team currently in control of the puck.
- `opposing_non_goalie_skater`: This feature tallies the number of skaters, excluding goalies, for the team without the puck.
- `attacking_side`: The side of the rink is being targeted in the event.
- `net_x`: The x-coordinate of the net being targeted.
- `net_distance`: The distance of the shooter from the net when the shot was taken.
- `distance_from_prev_distance`: The change in distance from the previous event to the current event.
- `shot_angle`: The angle of the shot relative to the net.
- `is_goal`: Indicates whether the shot resulted in a goal (1 for yes, 0 for no).
- `is_empty_net`: Indicates whether the net was empty when the goal was scored.
- `is_rebound`: Indicates whether the shot was a rebound.
- `change_in_shot_angle`: The change in the shot angle from the previous shot.
- `speed_of_change`: Defined as the distance from the previous event, divided by the time since the previous event.

Each of these features will help us to analyze the game with greater precision and insight.

This is the [link](https://www.comet.com/duyhung2201/ift-6758-b03-project/cbd721d275b147df8e7836a07890bb0a?experiment-tab=assetStorage) to the experiment storing a filtered dataframe for game 2017021065.

## 5. Advanced Models

### Baseline XGBoost classifier

![Alt text](../assets/milestone2/Question_5/default_XGB.png)

For this step, I used a training, validation split of 80/20. Since we have a large training set, this seemed like a good split to ensure there is sufficient data in both the training (for proper fitting) and validatidation set (so the metrics calculated are representative).
I used a preprocessing function to generate the split even though the features were very simple, because I was going to reuse it for later questions and it made the codebase cleaner.

Just using two features, it looks like the XGBoost model performs slightly better than the LogisticRegression classifier, but the difference is very slim. 
Looking at the first subplot, there is a marginal increase of the ROC from 0.7 to 0.71, thus showing that the model performs slightly better at correctly predicting goals. XGBoost are based on decision forests, but are boosted models with more capacity than Logistic regression, which might explain this difference. The difference will probably be higher as we get more features, because tree-based models are better at dealing with large dimension spaces.
The second and third subplots do not really show an obvious difference between the two classifiers and just looking at the curves do not show a significant difference in the ability of both classifiers to predict goal rate and cumulative goals.
Finally, looking at the calibration plots, we can see that both classifiers perform well until around 0.2 of predicted probability, but higher than that they start to diverge from the calibration plot. In the case of the XGB, the variance does not seem skewed and it both underestimate and overestimate the true probability since there are points on both sides of the calibration line.

[link](https://www.comet.com/duyhung2201/ift-6758-b03-project/1ff8722709a044d2bce04971ac0794c5?experiment-tab=panels&showOutliers=true&smoothing=0&xAxis=wall) to experiment

###  Hyperparameter tuning

For hyperparameter tuning, I decided to use an automatic optimization method to find the best hyperparameters. Since we are interested in the probability of goals and not only the actual prediction, I used log_loss as my metric for optimization since it relates more to probability.
I already had experience working with Optuna, which is a library to perform automatic optimization using a bayesian approach, which helps the model converge faster than simply using GridSearch and gives better results than RandomSearch from my experience.
Since we had to work with comet.ml, I decided to use their own optimization library so I could log my experiment more easily and generate figures related to the optimization process.
This type of library necessitates to have a dictionary of parameters, so I used a list from the official Optuna github with all the usual parameters for an XGBoost classifier. 

Link to dictionary : https://github.com/optuna/optuna-examples/blob/main/xgboost/xgboost_simple.py
This approach had the advantage of being exhaustive and not necessitating too much knowledge about each hyperparameter.

[link](https://www.comet.com/duyhung2201/ift-6758-b03-project/7834bc1dc7d845e5bd055797faf70a2c?experiment-tab=params) to best experiment

The XGBoost model has a lot of hyperparameters and choosing the best option is complex, because the choice of one hyperparameter influences the others. For instance, both alpha and lambda are a form of regularization, so if one of them is already high, the other can be lower and vice-versa. If the model is properly regularized, we can train for a long time without overfitting, but if the regularization parameters are low, the model might overfit with a large number of epochs. 
The following figure shows all the different combinations used during this optimization. The difficult is complex and hard to interpret, but its simply here to show that modifying one hyperparameter at a time is not enough, since we can see that every line zigzags up and down and even though one hyperparameter choice might seem like it lowers the accuracy, when combined with another hyperparameter it ends up being an advantageous choice.
![Alt text](../assets/milestone2/Question_5/hyperparemeters combinations.jpeg)

The following figure was created by using a custom report available on comet.ml to see the impact of each hyperparameter on the log_loss metric by using Spearman correlation.
The most important hyperparameter is eta which corresponds to the learning rate. This make sense intuitively, because if the learning rate is too high, the model will never converge and instead jump back and forth.
![Alt text](../assets/milestone2/Question_5/Spearman Correlation with logloss.png)

Finally, to further prove how complex hyperparameter tuning would be without using an agnostic approach like hyperparameter optimization, we can see below some of the hyperparameters for the 3 experiments with the lowest logloss.
Even though their logloss is very similar, they all have various combinations of hyperparameter that sometimes vary widely.
![Alt text](../assets/milestone2/Question_5/Top_3_experiments.png)

